{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe5598b",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c44088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b360073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6624f640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb032a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bb176d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>500.0</td>\n",
       "      <td>316.47200</td>\n",
       "      <td>11.295148</td>\n",
       "      <td>290.00</td>\n",
       "      <td>308.0000</td>\n",
       "      <td>317.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>340.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>500.0</td>\n",
       "      <td>107.19200</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>92.00</td>\n",
       "      <td>103.0000</td>\n",
       "      <td>107.00</td>\n",
       "      <td>112.00</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>500.0</td>\n",
       "      <td>3.11400</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>500.0</td>\n",
       "      <td>3.37400</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>500.0</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>0.925450</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>500.0</td>\n",
       "      <td>8.57644</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.1275</td>\n",
       "      <td>8.56</td>\n",
       "      <td>9.04</td>\n",
       "      <td>9.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.56000</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.72174</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count       mean        std     min       25%     50%  \\\n",
       "GRE Score          500.0  316.47200  11.295148  290.00  308.0000  317.00   \n",
       "TOEFL Score        500.0  107.19200   6.081868   92.00  103.0000  107.00   \n",
       "University Rating  500.0    3.11400   1.143512    1.00    2.0000    3.00   \n",
       "SOP                500.0    3.37400   0.991004    1.00    2.5000    3.50   \n",
       "LOR                500.0    3.48400   0.925450    1.00    3.0000    3.50   \n",
       "CGPA               500.0    8.57644   0.604813    6.80    8.1275    8.56   \n",
       "Research           500.0    0.56000   0.496884    0.00    0.0000    1.00   \n",
       "Chance of Admit    500.0    0.72174   0.141140    0.34    0.6300    0.72   \n",
       "\n",
       "                      75%     max  \n",
       "GRE Score          325.00  340.00  \n",
       "TOEFL Score        112.00  120.00  \n",
       "University Rating    4.00    5.00  \n",
       "SOP                  4.00    5.00  \n",
       "LOR                  4.00    5.00  \n",
       "CGPA                 9.04    9.92  \n",
       "Research             1.00    1.00  \n",
       "Chance of Admit      0.82    0.97  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157ec2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da807cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d6cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a46784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ce2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "710ea20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, activation = 'relu', input_dim = 7))\n",
    "model.add(Dense(7, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15f5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0da996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c56032a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 52ms/step - loss: 0.0557 - accuracy: 0.0000e+00 - val_loss: 0.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0286 - accuracy: 0.0000e+00 - val_loss: 0.0213 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0180 - accuracy: 0.0000e+00 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd0e9ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64359283],\n",
       "       [0.67754155],\n",
       "       [0.99325883],\n",
       "       [0.73240244],\n",
       "       [0.79246956],\n",
       "       [0.66243446],\n",
       "       [0.7400189 ],\n",
       "       [0.72166073],\n",
       "       [0.7777769 ],\n",
       "       [0.6626115 ],\n",
       "       [0.6821651 ],\n",
       "       [0.5389544 ],\n",
       "       [0.784489  ],\n",
       "       [0.7849929 ],\n",
       "       [0.75959826],\n",
       "       [0.8423435 ],\n",
       "       [0.61411595],\n",
       "       [0.7520551 ],\n",
       "       [0.92048985],\n",
       "       [0.6374271 ],\n",
       "       [0.6454589 ],\n",
       "       [0.76638937],\n",
       "       [0.82499915],\n",
       "       [0.5483379 ],\n",
       "       [0.7870092 ],\n",
       "       [0.55694383],\n",
       "       [0.9121694 ],\n",
       "       [0.65058106],\n",
       "       [0.827614  ],\n",
       "       [0.7087134 ],\n",
       "       [0.63773555],\n",
       "       [0.810857  ],\n",
       "       [0.5982836 ],\n",
       "       [0.87741566],\n",
       "       [0.50282234],\n",
       "       [0.7914763 ],\n",
       "       [0.6936692 ],\n",
       "       [0.6430158 ],\n",
       "       [0.6620117 ],\n",
       "       [0.8954525 ],\n",
       "       [0.53361756],\n",
       "       [0.6486878 ],\n",
       "       [0.7378376 ],\n",
       "       [0.9756209 ],\n",
       "       [0.74345696],\n",
       "       [0.51892513],\n",
       "       [0.64843094],\n",
       "       [0.62568015],\n",
       "       [0.67039645],\n",
       "       [0.6441466 ],\n",
       "       [0.8053543 ],\n",
       "       [0.88923174],\n",
       "       [0.91302687],\n",
       "       [0.61047995],\n",
       "       [0.75548667],\n",
       "       [0.6304757 ],\n",
       "       [0.7224707 ],\n",
       "       [0.6061614 ],\n",
       "       [0.65107983],\n",
       "       [0.67764187],\n",
       "       [0.41712505],\n",
       "       [0.6784635 ],\n",
       "       [0.75805753],\n",
       "       [0.8446806 ],\n",
       "       [0.96890944],\n",
       "       [0.61816794],\n",
       "       [0.72425574],\n",
       "       [0.7828757 ],\n",
       "       [0.92971814],\n",
       "       [0.7008522 ],\n",
       "       [0.5931949 ],\n",
       "       [0.63448864],\n",
       "       [0.78274816],\n",
       "       [0.45931995],\n",
       "       [0.9105683 ],\n",
       "       [0.5824616 ],\n",
       "       [0.8453172 ],\n",
       "       [0.89287645],\n",
       "       [0.69001037],\n",
       "       [0.7303094 ],\n",
       "       [0.8333476 ],\n",
       "       [0.49482703],\n",
       "       [0.9604103 ],\n",
       "       [0.7732002 ],\n",
       "       [0.8066763 ],\n",
       "       [0.68185335],\n",
       "       [0.8589869 ],\n",
       "       [0.9156768 ],\n",
       "       [0.57704455],\n",
       "       [0.56568015],\n",
       "       [0.6110629 ],\n",
       "       [0.78001964],\n",
       "       [0.5498939 ],\n",
       "       [0.68809855],\n",
       "       [0.788783  ],\n",
       "       [0.8050133 ],\n",
       "       [0.84495   ],\n",
       "       [0.54309076],\n",
       "       [0.74093133],\n",
       "       [0.70494694]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5701418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800604932714815"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76b45a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec38fd0460>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2276a3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec3907aa70>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6022e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
